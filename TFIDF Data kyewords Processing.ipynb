{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d78da0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged results saved: output/merged_output_tdf.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Enable tqdm progress bars\n",
    "tqdm.pandas()\n",
    "\n",
    "# File Paths\n",
    "data_path = \"data/\"\n",
    "output_path = \"output/\"\n",
    "output_file_path = os.path.join(output_path, \"merged_output_tdf.csv\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Target categories\n",
    "categories = ['chd', 'cold', 'depr', 'diab', 'lung', 'pneu']\n",
    "\n",
    "# TF-IDF Keyword Extraction Function\n",
    "def extract_tfidf_keywords(text_series, top_n=10):\n",
    "    \"\"\" Extracts top_n keywords for each row using TF-IDF \"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_df=0.9, min_df=2)\n",
    "    \n",
    "    # Transform text data\n",
    "    tfidf_matrix = vectorizer.fit_transform(text_series.fillna(''))  \n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    keywords_list = []\n",
    "    \n",
    "    for i in range(tfidf_matrix.shape[0]):\n",
    "        tfidf_scores = tfidf_matrix[i].toarray().flatten()\n",
    "        top_indices = np.argsort(tfidf_scores)[::-1][:top_n]\n",
    "        top_keywords = [feature_names[j] for j in top_indices if tfidf_scores[j] > 0]\n",
    "        keywords_list.append(\", \".join(top_keywords))\n",
    "    \n",
    "    return keywords_list\n",
    "\n",
    "# Process CSV data and extract keywords\n",
    "def process_category_to_jsonl():\n",
    "    all_dfs = []\n",
    "\n",
    "    # Load and merge all category data\n",
    "    for category in categories:\n",
    "        input_file = os.path.join(data_path, f\"{category}_inter.csv\")\n",
    "        try:\n",
    "            df = pd.read_csv(input_file, sep='\\t', dtype={\n",
    "                'pregnancy situation': int,\n",
    "                'gender': int,\n",
    "                'age': float,\n",
    "                'height': float,\n",
    "                'weight': float,\n",
    "                'duration of illness': float\n",
    "            })\n",
    "            df[\"category\"] = category \n",
    "            all_dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {input_file}: {e}\")\n",
    "    \n",
    "    # Merge all dataframes\n",
    "    if not all_dfs:\n",
    "        print(\"No data loaded. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    # Extract keywords from `text_all_patient`\n",
    "    df[\"keywords\"] = extract_tfidf_keywords(df[\"text_all_patient\"])\n",
    "\n",
    "    # Final dataframe with necessary columns\n",
    "    out_df = pd.DataFrame(columns=[\n",
    "        'description', 'gender', 'age', 'height', 'weight',\n",
    "        'pregnancy situation', 'duration of illness', 'category', 'disease', 'keywords'\n",
    "    ])\n",
    "\n",
    "    # Data processing\n",
    "    try:\n",
    "        out_df['description'] = df['text_all_patient'].fillna(\"\")\n",
    "        out_df[['age', 'height', 'weight', 'duration of illness']] = df[['age', 'height', 'weight', 'duration of illness']].fillna(0.0)\n",
    "        out_df['gender'] = df['gender'].fillna(0)\n",
    "        out_df['pregnancy situation'] = df['pregnancy situation'].fillna(0)\n",
    "        out_df['category'] = df['category']  \n",
    "        out_df['disease'] = df['disease_tag'].fillna(\"\")\n",
    "        out_df['keywords'] = df[\"keywords\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during data processing: {e}\")\n",
    "        return\n",
    "\n",
    "    # Save final results\n",
    "    out_df.to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "    print(f\"Final merged results saved: {output_file_path}\")\n",
    "\n",
    "# Main workflow\n",
    "def main():\n",
    "    process_category_to_jsonl()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34acfc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 30739/30739 [00:01<00:00, 21093.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged results saved: output/merged_output_tdf_new.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Enable tqdm progress bars\n",
    "tqdm.pandas()\n",
    "\n",
    "# File Paths\n",
    "data_path = \"data/\"\n",
    "output_path = \"output/\"\n",
    "output_file_path = os.path.join(output_path, \"merged_output_tdf_new.csv\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Target categories\n",
    "categories = ['chd', 'cold', 'depr', 'diab', 'lung', 'pneu']\n",
    "\n",
    "# TF-IDF Keyword Extraction Function\n",
    "def extract_tfidf_keywords(text_series, top_n=10):\n",
    "    \"\"\" Extracts top_n keywords for each row using TF-IDF \"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_df=0.9, min_df=2)\n",
    "    \n",
    "    # Transform text data\n",
    "    tfidf_matrix = vectorizer.fit_transform(text_series.fillna(''))  \n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    keywords_list = []\n",
    "    \n",
    "    for i in range(tfidf_matrix.shape[0]):\n",
    "        tfidf_scores = tfidf_matrix[i].toarray().flatten()\n",
    "        top_indices = np.argsort(tfidf_scores)[::-1][:top_n]\n",
    "        top_keywords = [feature_names[j] for j in top_indices if tfidf_scores[j] > 0]\n",
    "        keywords_list.append(\", \".join(top_keywords))\n",
    "    \n",
    "    return keywords_list\n",
    "\n",
    "# Function to combine structured data into textual description\n",
    "def combine_descriptions(row):\n",
    "    \"\"\" Combines text_all_patient with structured data fields into a single description \"\"\"\n",
    "    base_text = row['text_all_patient'] if pd.notnull(row['text_all_patient']) else \"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Process gender (0: male, 1: female)\n",
    "    gender = row['gender']\n",
    "    if gender in [0, 1]:\n",
    "        gender_str = 'male' if gender == 0 else 'female'\n",
    "        parts.append(f\"Gender: {gender_str}\")\n",
    "    \n",
    "    # Process age (ignore 0 values)\n",
    "    age = row['age']\n",
    "    if age > 0:\n",
    "        parts.append(f\"Age: {age} years\")\n",
    "    \n",
    "    # Process height (ignore 0 values)\n",
    "    height = row['height']\n",
    "    if height > 0:\n",
    "        parts.append(f\"Height: {height} cm\")\n",
    "    \n",
    "    # Process weight (ignore 0 values)\n",
    "    weight = row['weight']\n",
    "    if weight > 0:\n",
    "        parts.append(f\"Weight: {weight} kg\")\n",
    "    \n",
    "    # Process pregnancy situation (0: not pregnant, 1: pregnant)\n",
    "    pregnancy = row['pregnancy situation']\n",
    "    if pregnancy in [0, 1]:\n",
    "        preg_str = 'not pregnant' if pregnancy == 0 else 'pregnant'\n",
    "        parts.append(f\"Pregnancy situation: {preg_str}\")\n",
    "    \n",
    "    # Process duration of illness (ignore 0 values)\n",
    "    duration = row['duration of illness']\n",
    "    if duration > 0:\n",
    "        parts.append(f\"Duration of illness: {duration} days\")\n",
    "    \n",
    "    # Combine all parts\n",
    "    additional_info = \". \".join(parts)\n",
    "    if additional_info:\n",
    "        # Clean up existing punctuation\n",
    "        base_text = base_text.strip()\n",
    "        if base_text and not base_text.endswith('.'):\n",
    "            base_text += '.'\n",
    "        combined = f\"{additional_info} {base_text}.\"\n",
    "    else:\n",
    "        combined = base_text\n",
    "    \n",
    "    return combined.strip()\n",
    "\n",
    "# Process CSV data and extract keywords\n",
    "def process_category_to_jsonl():\n",
    "    all_dfs = []\n",
    "\n",
    "    # Load and merge all category data\n",
    "    for category in categories:\n",
    "        input_file = os.path.join(data_path, f\"{category}_inter.csv\")\n",
    "        try:\n",
    "            df = pd.read_csv(input_file, sep='\\t', dtype={\n",
    "                'pregnancy situation': int,\n",
    "                'gender': int,\n",
    "                'age': float,\n",
    "                'height': float,\n",
    "                'weight': float,\n",
    "                'duration of illness': float\n",
    "            })\n",
    "            df[\"category\"] = category  # Add category column\n",
    "            all_dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {input_file}: {e}\")\n",
    "    \n",
    "    # Merge all dataframes\n",
    "    if not all_dfs:\n",
    "        print(\"No data loaded. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    # Extract keywords from the new description field\n",
    "    df[\"keywords\"] = extract_tfidf_keywords(df[\"text_all_patient\"])\n",
    "    \n",
    "    # Generate combined description field\n",
    "    df[\"description\"] = df.progress_apply(combine_descriptions, axis=1)  # Using progress_apply for visual feedback\n",
    "\n",
    "    \n",
    "    # Create final output dataframe\n",
    "    out_df = df[['description', 'category', 'disease_tag', 'keywords','age', 'height', 'weight', 'duration of illness','gender','pregnancy situation']].copy()\n",
    "    out_df.rename(columns={'disease_tag': 'disease'}, inplace=True)\n",
    "    \n",
    "    # Handle missing values\n",
    "    out_df.fillna({\n",
    "        'description': '',\n",
    "        'disease': '',\n",
    "        'category': '',\n",
    "        'keywords': ''\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Save final results\n",
    "    out_df.to_csv(output_file_path, index=False, encoding='utf-8')\n",
    "    print(f\"Final merged results saved: {output_file_path}\")\n",
    "\n",
    "# Main workflow\n",
    "def main():\n",
    "    process_category_to_jsonl()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('start')\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6edefc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8314e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5ec8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276dee6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
